{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test[[\"value_amoni\",\"value_water\",\"value\",\"mes\",\"dia\",\"hora\",\"minuts\"]].to_numpy()\n",
    "test_label = test[[\"is_drift\",\"dangerous_drift\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train[[\"value_amoni\",\"value_water\",\"value\",\"mes\",\"dia\",\"hora\",\"minuts\"]].to_numpy()\n",
    "train_label = train[[\"is_drift\",\"dangerous_drift\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MODEL= 0.546 --> model = keras.Sequential([\n",
    "    keras.layers.Dense(20,input_shape =(7,)),  # input layer (1)\n",
    "    keras.layers.Dense(10, activation='sigmoid'),\n",
    "    keras.layers.Dense(5, activation='sigmoid'), \n",
    "    keras.layers.Dense(3, activation='sigmoid'), # hidden layer (2)\n",
    "    keras.layers.Dense(2, activation='sigmoid') # output layer (3)\n",
    "])'''\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(7,input_shape =(7,)),  # input layer (1)\n",
    "    keras.layers.Dense(14, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid'), \n",
    "    keras.layers.Dense(6, activation='sigmoid'), # hidden layer (2)\n",
    "    keras.layers.Dense(2, activation='sigmoid') # output layer (3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.2605 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 1.0000\n",
      "Epoch 2/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
      "Epoch 3/250\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.2272 - accuracy: 0.8624 - val_loss: 0.2024 - val_accuracy: 0.5741\n",
      "Epoch 4/250\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.5922 - val_loss: 0.0913 - val_accuracy: 0.5810\n",
      "Epoch 5/250\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.5797 - val_loss: 0.0381 - val_accuracy: 0.5810\n",
      "Epoch 6/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.5797 - val_loss: 0.0203 - val_accuracy: 0.5810\n",
      "Epoch 7/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.5797 - val_loss: 0.0128 - val_accuracy: 0.5810\n",
      "Epoch 8/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.5797 - val_loss: 0.0090 - val_accuracy: 0.5810\n",
      "Epoch 9/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.5797 - val_loss: 0.0067 - val_accuracy: 0.5810\n",
      "Epoch 10/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.5797 - val_loss: 0.0053 - val_accuracy: 0.5810\n",
      "Epoch 11/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.5797 - val_loss: 0.0042 - val_accuracy: 0.5810\n",
      "Epoch 12/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.5797 - val_loss: 0.0035 - val_accuracy: 0.5810\n",
      "Epoch 13/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.5797 - val_loss: 0.0029 - val_accuracy: 0.5810\n",
      "Epoch 14/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.5797 - val_loss: 0.0025 - val_accuracy: 0.5810\n",
      "Epoch 15/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.5797 - val_loss: 0.0021 - val_accuracy: 0.5810\n",
      "Epoch 16/250\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.5797 - val_loss: 0.0018 - val_accuracy: 0.5810\n",
      "Epoch 17/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.5797 - val_loss: 0.0016 - val_accuracy: 0.5810\n",
      "Epoch 18/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.5797 - val_loss: 0.0014 - val_accuracy: 0.5810\n",
      "Epoch 19/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.5797 - val_loss: 0.0013 - val_accuracy: 0.5810\n",
      "Epoch 20/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.5797 - val_loss: 0.0011 - val_accuracy: 0.5810\n",
      "Epoch 21/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.5797 - val_loss: 9.9841e-04 - val_accuracy: 0.5810\n",
      "Epoch 22/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.4758e-04 - accuracy: 0.5797 - val_loss: 8.9514e-04 - val_accuracy: 0.5810\n",
      "Epoch 23/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 8.5083e-04 - accuracy: 0.5797 - val_loss: 8.0503e-04 - val_accuracy: 0.5810\n",
      "Epoch 24/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.6640e-04 - accuracy: 0.5797 - val_loss: 7.2636e-04 - val_accuracy: 0.5810\n",
      "Epoch 25/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.9227e-04 - accuracy: 0.5797 - val_loss: 6.5705e-04 - val_accuracy: 0.5810\n",
      "Epoch 26/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.2687e-04 - accuracy: 0.5797 - val_loss: 5.9546e-04 - val_accuracy: 0.5810\n",
      "Epoch 27/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.6894e-04 - accuracy: 0.5797 - val_loss: 5.4116e-04 - val_accuracy: 0.5810\n",
      "Epoch 28/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.1743e-04 - accuracy: 0.5797 - val_loss: 4.9259e-04 - val_accuracy: 0.5810\n",
      "Epoch 29/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.7141e-04 - accuracy: 0.5797 - val_loss: 4.4921e-04 - val_accuracy: 0.5810\n",
      "Epoch 30/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.3021e-04 - accuracy: 0.5797 - val_loss: 4.1031e-04 - val_accuracy: 0.5810\n",
      "Epoch 31/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.9320e-04 - accuracy: 0.5797 - val_loss: 3.7531e-04 - val_accuracy: 0.5810\n",
      "Epoch 32/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.5988e-04 - accuracy: 0.5797 - val_loss: 3.4371e-04 - val_accuracy: 0.5810\n",
      "Epoch 33/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.2979e-04 - accuracy: 0.5797 - val_loss: 3.1514e-04 - val_accuracy: 0.5810\n",
      "Epoch 34/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.0256e-04 - accuracy: 0.5797 - val_loss: 2.8932e-04 - val_accuracy: 0.5810\n",
      "Epoch 35/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.7788e-04 - accuracy: 0.5797 - val_loss: 2.6580e-04 - val_accuracy: 0.5810\n",
      "Epoch 36/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.5544e-04 - accuracy: 0.5797 - val_loss: 2.4448e-04 - val_accuracy: 0.5810\n",
      "Epoch 37/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.3503e-04 - accuracy: 0.5797 - val_loss: 2.2504e-04 - val_accuracy: 0.5810\n",
      "Epoch 38/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.1642e-04 - accuracy: 0.5797 - val_loss: 2.0732e-04 - val_accuracy: 0.5810\n",
      "Epoch 39/250\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 1.9943e-04 - accuracy: 0.5797 - val_loss: 1.9109e-04 - val_accuracy: 0.5810\n",
      "Epoch 40/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.8390e-04 - accuracy: 0.5797 - val_loss: 1.7628e-04 - val_accuracy: 0.5810\n",
      "Epoch 41/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.6969e-04 - accuracy: 0.5797 - val_loss: 1.6269e-04 - val_accuracy: 0.5810\n",
      "Epoch 42/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.5667e-04 - accuracy: 0.5797 - val_loss: 1.5027e-04 - val_accuracy: 0.5810\n",
      "Epoch 43/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.4472e-04 - accuracy: 0.5797 - val_loss: 1.3886e-04 - val_accuracy: 0.5810\n",
      "Epoch 44/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.3376e-04 - accuracy: 0.5797 - val_loss: 1.2835e-04 - val_accuracy: 0.5810\n",
      "Epoch 45/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.2367e-04 - accuracy: 0.5797 - val_loss: 1.1871e-04 - val_accuracy: 0.5810\n",
      "Epoch 46/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.1441e-04 - accuracy: 0.5797 - val_loss: 1.0983e-04 - val_accuracy: 0.5810\n",
      "Epoch 47/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.0587e-04 - accuracy: 0.5797 - val_loss: 1.0166e-04 - val_accuracy: 0.5810\n",
      "Epoch 48/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.8012e-05 - accuracy: 0.5797 - val_loss: 9.4119e-05 - val_accuracy: 0.5810\n",
      "Epoch 49/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.0766e-05 - accuracy: 0.5797 - val_loss: 8.7195e-05 - val_accuracy: 0.5810\n",
      "Epoch 50/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 8.4084e-05 - accuracy: 0.5797 - val_loss: 8.0778e-05 - val_accuracy: 0.5810\n",
      "Epoch 51/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.7913e-05 - accuracy: 0.5797 - val_loss: 7.4871e-05 - val_accuracy: 0.5810\n",
      "Epoch 52/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.2218e-05 - accuracy: 0.5797 - val_loss: 6.9405e-05 - val_accuracy: 0.5810\n",
      "Epoch 53/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.6956e-05 - accuracy: 0.5797 - val_loss: 6.4353e-05 - val_accuracy: 0.5810\n",
      "Epoch 54/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.2092e-05 - accuracy: 0.5797 - val_loss: 5.9675e-05 - val_accuracy: 0.5810\n",
      "Epoch 55/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.7593e-05 - accuracy: 0.5797 - val_loss: 5.5366e-05 - val_accuracy: 0.5810\n",
      "Epoch 56/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.3432e-05 - accuracy: 0.5797 - val_loss: 5.1369e-05 - val_accuracy: 0.5810\n",
      "Epoch 57/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.9580e-05 - accuracy: 0.5797 - val_loss: 4.7672e-05 - val_accuracy: 0.5810\n",
      "Epoch 58/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.6014e-05 - accuracy: 0.5797 - val_loss: 4.4249e-05 - val_accuracy: 0.5810\n",
      "Epoch 59/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.2711e-05 - accuracy: 0.5797 - val_loss: 4.1077e-05 - val_accuracy: 0.5810\n",
      "Epoch 60/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.9653e-05 - accuracy: 0.5797 - val_loss: 3.8131e-05 - val_accuracy: 0.5810\n",
      "Epoch 61/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.6818e-05 - accuracy: 0.5797 - val_loss: 3.5415e-05 - val_accuracy: 0.5810\n",
      "Epoch 62/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.4191e-05 - accuracy: 0.5797 - val_loss: 3.2888e-05 - val_accuracy: 0.5810\n",
      "Epoch 63/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.1756e-05 - accuracy: 0.5797 - val_loss: 3.0543e-05 - val_accuracy: 0.5810\n",
      "Epoch 64/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.9497e-05 - accuracy: 0.5797 - val_loss: 2.8379e-05 - val_accuracy: 0.5810\n",
      "Epoch 65/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.7403e-05 - accuracy: 0.5797 - val_loss: 2.6361e-05 - val_accuracy: 0.5810\n",
      "Epoch 66/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.5460e-05 - accuracy: 0.5797 - val_loss: 2.4493e-05 - val_accuracy: 0.5810\n",
      "Epoch 67/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.3657e-05 - accuracy: 0.5797 - val_loss: 2.2763e-05 - val_accuracy: 0.5810\n",
      "Epoch 68/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.1984e-05 - accuracy: 0.5797 - val_loss: 2.1154e-05 - val_accuracy: 0.5810\n",
      "Epoch 69/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.0430e-05 - accuracy: 0.5797 - val_loss: 1.9660e-05 - val_accuracy: 0.5810\n",
      "Epoch 70/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.8989e-05 - accuracy: 0.5797 - val_loss: 1.8273e-05 - val_accuracy: 0.5810\n",
      "Epoch 71/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.7650e-05 - accuracy: 0.5797 - val_loss: 1.6984e-05 - val_accuracy: 0.5810\n",
      "Epoch 72/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.6407e-05 - accuracy: 0.5797 - val_loss: 1.5790e-05 - val_accuracy: 0.5810\n",
      "Epoch 73/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.5253e-05 - accuracy: 0.5797 - val_loss: 1.4675e-05 - val_accuracy: 0.5810\n",
      "Epoch 74/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.4180e-05 - accuracy: 0.5797 - val_loss: 1.3646e-05 - val_accuracy: 0.5810\n",
      "Epoch 75/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.3184e-05 - accuracy: 0.5797 - val_loss: 1.2689e-05 - val_accuracy: 0.5810\n",
      "Epoch 76/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.2258e-05 - accuracy: 0.5797 - val_loss: 1.1799e-05 - val_accuracy: 0.5810\n",
      "Epoch 77/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.1398e-05 - accuracy: 0.5797 - val_loss: 1.0971e-05 - val_accuracy: 0.5810\n",
      "Epoch 78/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.0600e-05 - accuracy: 0.5797 - val_loss: 1.0202e-05 - val_accuracy: 0.5810\n",
      "Epoch 79/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.8568e-06 - accuracy: 0.5797 - val_loss: 9.4883e-06 - val_accuracy: 0.5810\n",
      "Epoch 80/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.1668e-06 - accuracy: 0.5797 - val_loss: 8.8235e-06 - val_accuracy: 0.5810\n",
      "Epoch 81/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 8.5253e-06 - accuracy: 0.5797 - val_loss: 8.2071e-06 - val_accuracy: 0.5810\n",
      "Epoch 82/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.9295e-06 - accuracy: 0.5797 - val_loss: 7.6320e-06 - val_accuracy: 0.5810\n",
      "Epoch 83/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.3752e-06 - accuracy: 0.5797 - val_loss: 7.0988e-06 - val_accuracy: 0.5810\n",
      "Epoch 84/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.8599e-06 - accuracy: 0.5797 - val_loss: 6.6037e-06 - val_accuracy: 0.5810\n",
      "Epoch 85/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.3810e-06 - accuracy: 0.5797 - val_loss: 6.1435e-06 - val_accuracy: 0.5810\n",
      "Epoch 86/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.9358e-06 - accuracy: 0.5797 - val_loss: 5.7144e-06 - val_accuracy: 0.5810\n",
      "Epoch 87/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.5219e-06 - accuracy: 0.5797 - val_loss: 5.3157e-06 - val_accuracy: 0.5810\n",
      "Epoch 88/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.1370e-06 - accuracy: 0.5797 - val_loss: 4.9450e-06 - val_accuracy: 0.5810\n",
      "Epoch 89/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.7790e-06 - accuracy: 0.5797 - val_loss: 4.6009e-06 - val_accuracy: 0.5810\n",
      "Epoch 90/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.4462e-06 - accuracy: 0.5797 - val_loss: 4.2811e-06 - val_accuracy: 0.5810\n",
      "Epoch 91/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.1367e-06 - accuracy: 0.5797 - val_loss: 3.9824e-06 - val_accuracy: 0.5810\n",
      "Epoch 92/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.8487e-06 - accuracy: 0.5797 - val_loss: 3.7061e-06 - val_accuracy: 0.5810\n",
      "Epoch 93/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.5811e-06 - accuracy: 0.5797 - val_loss: 3.4485e-06 - val_accuracy: 0.5810\n",
      "Epoch 94/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.3321e-06 - accuracy: 0.5797 - val_loss: 3.2086e-06 - val_accuracy: 0.5810\n",
      "Epoch 95/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.1006e-06 - accuracy: 0.5797 - val_loss: 2.9853e-06 - val_accuracy: 0.5810\n",
      "Epoch 96/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.8852e-06 - accuracy: 0.5797 - val_loss: 2.7785e-06 - val_accuracy: 0.5810\n",
      "Epoch 97/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.6849e-06 - accuracy: 0.5797 - val_loss: 2.5857e-06 - val_accuracy: 0.5810\n",
      "Epoch 98/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.4986e-06 - accuracy: 0.5797 - val_loss: 2.4061e-06 - val_accuracy: 0.5810\n",
      "Epoch 99/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.3253e-06 - accuracy: 0.5797 - val_loss: 2.2391e-06 - val_accuracy: 0.5810\n",
      "Epoch 100/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.1641e-06 - accuracy: 0.5797 - val_loss: 2.0839e-06 - val_accuracy: 0.5810\n",
      "Epoch 101/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.0141e-06 - accuracy: 0.5797 - val_loss: 1.9398e-06 - val_accuracy: 0.5810\n",
      "Epoch 102/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.8747e-06 - accuracy: 0.5797 - val_loss: 1.8053e-06 - val_accuracy: 0.5810\n",
      "Epoch 103/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.7450e-06 - accuracy: 0.5797 - val_loss: 1.6802e-06 - val_accuracy: 0.5810\n",
      "Epoch 104/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.6242e-06 - accuracy: 0.5797 - val_loss: 1.5642e-06 - val_accuracy: 0.5810\n",
      "Epoch 105/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.5119e-06 - accuracy: 0.5797 - val_loss: 1.4562e-06 - val_accuracy: 0.5810\n",
      "Epoch 106/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.4075e-06 - accuracy: 0.5797 - val_loss: 1.3556e-06 - val_accuracy: 0.5810\n",
      "Epoch 107/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.3103e-06 - accuracy: 0.5797 - val_loss: 1.2618e-06 - val_accuracy: 0.5810\n",
      "Epoch 108/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.2198e-06 - accuracy: 0.5797 - val_loss: 1.1751e-06 - val_accuracy: 0.5810\n",
      "Epoch 109/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.1357e-06 - accuracy: 0.5797 - val_loss: 1.0939e-06 - val_accuracy: 0.5810\n",
      "Epoch 110/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.0574e-06 - accuracy: 0.5797 - val_loss: 1.0186e-06 - val_accuracy: 0.5810\n",
      "Epoch 111/250\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 9.8462e-07 - accuracy: 0.5797 - val_loss: 9.4844e-07 - val_accuracy: 0.5810\n",
      "Epoch 112/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 9.1689e-07 - accuracy: 0.5797 - val_loss: 8.8319e-07 - val_accuracy: 0.5810\n",
      "Epoch 113/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 8.5386e-07 - accuracy: 0.5797 - val_loss: 8.2237e-07 - val_accuracy: 0.5810\n",
      "Epoch 114/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.9518e-07 - accuracy: 0.5797 - val_loss: 7.6607e-07 - val_accuracy: 0.5810\n",
      "Epoch 115/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 7.4063e-07 - accuracy: 0.5797 - val_loss: 7.1344e-07 - val_accuracy: 0.5810\n",
      "Epoch 116/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.8984e-07 - accuracy: 0.5797 - val_loss: 6.6456e-07 - val_accuracy: 0.5810\n",
      "Epoch 117/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 6.4260e-07 - accuracy: 0.5797 - val_loss: 6.1908e-07 - val_accuracy: 0.5810\n",
      "Epoch 118/250\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 5.9865e-07 - accuracy: 0.5797 - val_loss: 5.7672e-07 - val_accuracy: 0.5810\n",
      "Epoch 119/250\n",
      " 33/145 [=====>........................] - ETA: 0s - loss: 5.7592e-07 - accuracy: 0.5758"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53789/882367030.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    303\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m     \"\"\"\n\u001b[0;32m-> 3655\u001b[0;31m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0m\u001b[1;32m   3656\u001b[0m                     overwrite_input=overwrite_input)\n\u001b[1;32m   3657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_ureduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m     \"\"\"\n\u001b[1;32m   3515\u001b[0m     \u001b[0mInternal\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input, train_label, epochs=250,validation_data=(test_input,test_label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 5.2367e-09 - accuracy: 0.5810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.236745259651343e-09, 0.5810344815254211]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,251)\n",
    "plt.plot(epochs, loss_train, 'g', label='training_loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
